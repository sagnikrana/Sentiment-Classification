{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from utils.utils import build_freqs, process_tweet\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "import warnings\n",
    "from sys import getsizeof\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To be optimized later with generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalysis:\n",
    "    \n",
    "    def __init__(self, trainingSplit, tweets_df):\n",
    "        self.trainingSplit = trainingSplit\n",
    "        self.tweets_df = tweets_df\n",
    "    \n",
    "    def getCleanDataFrame(self, df):\n",
    "        df = df[[0, 5]]\n",
    "        df[0] = df[0].map({0:0, 4:1})\n",
    "        df.rename(columns = {0:'sentiment', 5:'tweet'}, inplace = True)\n",
    "        self.tweets_df = df\n",
    "        return df\n",
    "    \n",
    "    def extract_features(self, tweet, freqs):\n",
    "\n",
    "        word_l = process_tweet(tweet)\n",
    "        \n",
    "        x = np.zeros((1, 3)) \n",
    "        \n",
    "        x[0,0] = 1 \n",
    "\n",
    "        for word in word_l:\n",
    "\n",
    "            x[0,1] += freqs.get((word, 1.0),0)\n",
    "            x[0,2] += freqs.get((word, 0.0),0)\n",
    "\n",
    "        assert(x.shape == (1, 3))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def performTrainDevTestSplit(self):\n",
    "        positive = self.tweets_df.query('sentiment == 1')\n",
    "        negative = self.tweets_df.query('sentiment == 0')\n",
    "        \n",
    "        print(positive.head())\n",
    "        print(negative.head())\n",
    "        \n",
    "        pos_observations = positive.shape[0]\n",
    "        neg_observations = negative.shape[0]\n",
    "        \n",
    "        total_observations = positive.shape[0]\n",
    "        devLen = testLen = math.floor(((100 - self.trainingSplit)/2) * pos_observations * 0.01)\n",
    "        trainLen = math.floor(pos_observations * self.trainingSplit * 0.01)\n",
    "        \n",
    "        train_pos_x = list(positive['tweet'].iloc[0:trainLen])\n",
    "        train_pos_y = list(positive['sentiment'].iloc[0:trainLen])\n",
    "        dev_pos_x = list(positive['tweet'].iloc[trainLen:total_observations - testLen])\n",
    "        dev_pos_y = list(positive['sentiment'].iloc[trainLen:total_observations - testLen])\n",
    "        test_pos_x = list(positive['tweet'].iloc[trainLen + devLen:])\n",
    "        test_pos_y = list(positive['sentiment'].iloc[trainLen + devLen:])\n",
    "        \n",
    "        total_observations = negative.shape[0]\n",
    "        devLen = testLen = math.floor(((100 - self.trainingSplit)/2) * neg_observations * 0.01)\n",
    "        trainLen = math.floor(neg_observations * self.trainingSplit * 0.01)\n",
    "\n",
    "        train_neg_x = list(negative['tweet'].iloc[0:trainLen])\n",
    "        train_neg_y = list(negative['sentiment'].iloc[0:trainLen])\n",
    "        dev_neg_x = list(negative['tweet'].iloc[trainLen:total_observations - testLen])\n",
    "        dev_neg_y = list(negative['sentiment'].iloc[trainLen:total_observations - testLen])\n",
    "        test_neg_x = list(negative['tweet'].iloc[trainLen + devLen:])\n",
    "        test_neg_y = list(negative['sentiment'].iloc[trainLen + devLen:])\n",
    "        \n",
    "\n",
    "        train_x = train_pos_x + train_neg_x\n",
    "        train_y = train_pos_y + train_neg_y\n",
    "        dev_x = dev_pos_x + dev_neg_x\n",
    "        dev_y = dev_pos_y + dev_neg_y\n",
    "        test_x = test_pos_x + test_neg_x\n",
    "        test_y = test_pos_y + test_neg_y\n",
    "        \n",
    "        return (train_x, train_y, dev_x, dev_y, test_x, test_y)\n",
    "    \n",
    "    def getTrainDevTorchTensors(self, datasets):\n",
    "        dataset_arrays = []\n",
    "        for Xi, Y in datasets:\n",
    "            print(f'X len: {len(Xi)}')\n",
    "            print(f'Y len: {len(Y)}')\n",
    "            freqs = build_freqs(Xi, Y)\n",
    "            X = np.zeros((len(Xi), 3))\n",
    "            for i in range(len(X)):\n",
    "                X[i, :]= sentiment.extract_features(Xi[i], freqs)\n",
    "\n",
    "            # training labels corresponding to X\n",
    "            Y = torch.from_numpy(np.array(Y)).float()\n",
    "            \n",
    "            dataset_arrays.append(torch.from_numpy(X).float())\n",
    "            dataset_arrays.append(Y.reshape(len(X),1))\n",
    "        \n",
    "        return tuple(dataset_arrays)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets:  1600000\n",
      "\n",
      " *************** \n",
      "\n",
      "        sentiment                                              tweet\n",
      "800000          1       I LOVE @Health4UandPets u guys r the best!! \n",
      "800001          1  im meeting up with one of my besties tonight! ...\n",
      "800002          1  @DaRealSunisaKim Thanks for the Twitter add, S...\n",
      "800003          1  Being sick can be really cheap when it hurts t...\n",
      "800004          1    @LovesBrooklyn2 he has that effect on everyone \n",
      "   sentiment                                              tweet\n",
      "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
      "1          0  is upset that he can't update his Facebook by ...\n",
      "2          0  @Kenichan I dived many times for the ball. Man...\n",
      "3          0    my whole body feels itchy and like its on fire \n",
      "4          0  @nationwideclass no, it's not behaving at all....\n",
      "X len: 1552000\n",
      "Y len: 1552000\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    tweets_df = pd.read_csv(\"data/tweets.csv\", encoding = \"ISO-8859-1\", header=None)\n",
    "#     tweets_df = pd.read_csv(\"data/tweets.csv\", encoding = \"utf-8\", header=None)\n",
    "    \n",
    "#     tweets_df_1 = tweets_df.iloc[:100]\n",
    "#     tweets_df_2 = tweets_df.iloc[len(tweets_df)-100:]\n",
    "#     tweets_df = tweets_df_1.append(tweets_df_2)\n",
    "    \n",
    "    print('Total number of tweets: ',tweets_df.shape[0])\n",
    "    print('\\n *************** \\n')\n",
    "    sentiment = SentimentAnalysis(97, tweets_df)\n",
    "    tweets_df = sentiment.getCleanDataFrame(tweets_df)\n",
    "    train_x, train_y, dev_x, dev_y, test_x, test_y = sentiment.performTrainDevTestSplit()\n",
    "    train_X, train_Y, dev_X, dev_Y, test_X, test_Y = sentiment.getTrainDevTestArray([(train_x, train_y), (dev_x, dev_y), (test_x, test_y)])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Design Model (input, output, forward pass) <br>\n",
    "2. Construct loss and optimizer <br>\n",
    "3. Training Loop:\n",
    " - forward pass : compute prediction and loss\n",
    " - backward pass: gradients\n",
    " - update weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "class LogisticRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "    \n",
    "\n",
    "model = LogisticRegression(train_X.shape[1])\n",
    "\n",
    "# Loss and Optimizer\n",
    "\n",
    "learning_rate = 0.01\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# training loop\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # forward pass and loss\n",
    "    y_pred = model.forward(train_X)\n",
    "    loss = criterion(y_pred, train_Y)\n",
    "    # backward \n",
    "    loss.backward()\n",
    "    # updates\n",
    "    optimizer.step()\n",
    "    # reset the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch+1)%10 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
    "        \n",
    "with torch.no_grad():\n",
    "    y_pred = model.forward(test_X)\n",
    "    y_pred_cls = y_pred.round()\n",
    "    acc = y_pred_cls.eq(test_Y).sum() / float(test_Y.shape[0])\n",
    "    print(f'Accuracy {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
