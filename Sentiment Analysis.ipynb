{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from utils.utils import build_freqs, process_tweet\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "import warnings\n",
    "from sys import getsizeof\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To be optimized later with generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalysis:\n",
    "    \n",
    "    def __init__(self, trainingSplit, tweets_df):\n",
    "        self.trainingSplit = trainingSplit\n",
    "        self.tweets_df = tweets_df\n",
    "    \n",
    "    def getCleanDataFrame(self, df):\n",
    "        df = df[[0, 5]]\n",
    "        df[0] = df[0].map({0:-1, 4:1})\n",
    "        df.rename(columns = {0:'sentiment', 5:'tweet'}, inplace = True)\n",
    "        self.tweets_df = df\n",
    "        return df\n",
    "    \n",
    "    def extract_features(self, tweet, freqs):\n",
    "\n",
    "        word_l = process_tweet(tweet)\n",
    "        \n",
    "        x = np.zeros((1, 3)) \n",
    "        \n",
    "        x[0,0] = 1 \n",
    "\n",
    "        for word in word_l:\n",
    "\n",
    "            x[0,1] += freqs.get((word, 1.0),0)\n",
    "            x[0,2] += freqs.get((word, 0.0),0)\n",
    "\n",
    "        assert(x.shape == (1, 3))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def performTrainDevTestSplit(self):\n",
    "        positive = self.tweets_df.query('sentiment == 1')\n",
    "        negative = self.tweets_df.query('sentiment == -1')\n",
    "        \n",
    "        print(positive.head())\n",
    "        print(negative.head())\n",
    "        \n",
    "        pos_observations = positive.shape[0]\n",
    "        neg_observations = negative.shape[0]\n",
    "        \n",
    "        devLen = testLen = math.floor(((100 - self.trainingSplit)/2) * pos_observations * 0.01)\n",
    "        trainLen = math.floor(pos_observations * self.trainingSplit * 0.01)\n",
    "        \n",
    "        train_pos_x = list(positive['tweet'].iloc[0:trainLen])\n",
    "        train_pos_y = list(positive['sentiment'].iloc[0:trainLen])\n",
    "        dev_pos_x = list(positive['tweet'].iloc[trainLen:devLen])\n",
    "        dev_pos_y = list(positive['sentiment'].iloc[trainLen:devLen])\n",
    "        test_pos_x = list(positive['tweet'].iloc[testLen:])\n",
    "        test_pos_y = list(positive['sentiment'].iloc[testLen:])\n",
    "        \n",
    "        devLen = testLen = math.floor(((100 - self.trainingSplit)/2) * neg_observations * 0.01)\n",
    "        trainLen = math.floor(neg_observations * self.trainingSplit * 0.01)\n",
    "        \n",
    "        train_neg_x = list(negative['tweet'].iloc[0:trainLen])\n",
    "        train_neg_y = list(negative['sentiment'].iloc[0:trainLen])\n",
    "        dev_neg_x = list(negative['tweet'].iloc[trainLen:devLen])\n",
    "        dev_neg_y = list(negative['sentiment'].iloc[trainLen:devLen])\n",
    "        test_neg_x = list(negative['tweet'].iloc[testLen:])\n",
    "        test_neg_y = list(negative['sentiment'].iloc[testLen:])\n",
    "        \n",
    "        train_x = train_pos_x + train_neg_x\n",
    "        train_y = train_pos_y + train_neg_y\n",
    "        dev_x = dev_pos_x + dev_neg_x\n",
    "        dev_y = dev_pos_y + dev_neg_y\n",
    "        test_x = test_pos_x + test_neg_x\n",
    "        test_y = test_pos_y + test_neg_y\n",
    "        \n",
    "        return (train_x, train_y, dev_x, dev_y, test_x, test_y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets:  1600000\n",
      "\n",
      " *************** \n",
      "\n",
      "        sentiment                                              tweet\n",
      "800000          1       I LOVE @Health4UandPets u guys r the best!! \n",
      "800001          1  im meeting up with one of my besties tonight! ...\n",
      "800002          1  @DaRealSunisaKim Thanks for the Twitter add, S...\n",
      "800003          1  Being sick can be really cheap when it hurts t...\n",
      "800004          1    @LovesBrooklyn2 he has that effect on everyone \n",
      "   sentiment                                              tweet\n",
      "0         -1  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
      "1         -1  is upset that he can't update his Facebook by ...\n",
      "2         -1  @Kenichan I dived many times for the ball. Man...\n",
      "3         -1    my whole body feels itchy and like its on fire \n",
      "4         -1  @nationwideclass no, it's not behaving at all....\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    tweets_df = pd.read_csv(\"data/tweets.csv\", encoding = \"ISO-8859-1\", header=None)\n",
    "    print('Total number of tweets: ',tweets_df.shape[0])\n",
    "    print('\\n *************** \\n')\n",
    "    sentiment = SentimentAnalysis(95, tweets_df)\n",
    "    tweets_df = sentiment.getCleanDataFrame(tweets_df)\n",
    "    train_x, train_y, dev_x, dev_y, test_x, test_y = sentiment.performTrainDevTestSplit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.e+00, 5.e+03, 0.e+00]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = build_freqs(train_x, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(train_x), 3))\n",
    "for i in range(len(train_x)):\n",
    "    X[i, :]= sentiment.extract_features(train_x[i], freqs)\n",
    "\n",
    "# training labels corresponding to X\n",
    "Y = train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Design Model (input, output, forward pass) <br>\n",
    "2. Construct loss and optimizer <br>\n",
    "3. Training Loop:\n",
    " - forward pass : compute prediction and loss\n",
    " - backward pass: gradients\n",
    " - update weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
