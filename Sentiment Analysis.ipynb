{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from utils.utils import build_freqs, process_tweet\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "import warnings\n",
    "from sys import getsizeof\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To be optimized later with generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalysis:\n",
    "    \n",
    "    def __init__(self, trainingSplit, tweets_df):\n",
    "        self.trainingSplit = trainingSplit\n",
    "        self.tweets_df = tweets_df\n",
    "    \n",
    "    def getCleanDataFrame(self, df):\n",
    "        df = df[[0, 5]]\n",
    "        df[0] = df[0].map({0:0, 4:1})\n",
    "        df.rename(columns = {0:'sentiment', 5:'tweet'}, inplace = True)\n",
    "        self.tweets_df = df\n",
    "        return df\n",
    "    \n",
    "    def extract_features(self, tweet, freqs):\n",
    "\n",
    "        word_l = process_tweet(tweet)\n",
    "        \n",
    "        x = np.zeros((1, 3)) \n",
    "        \n",
    "        x[0,0] = 1 \n",
    "\n",
    "        for word in word_l:\n",
    "\n",
    "            x[0,1] += freqs.get((word, 1.0),0)\n",
    "            x[0,2] += freqs.get((word, 0.0),0)\n",
    "\n",
    "        assert(x.shape == (1, 3))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def performTrainDevTestSplit(self):\n",
    "        positive = self.tweets_df.query('sentiment == 1')\n",
    "        negative = self.tweets_df.query('sentiment == 0')\n",
    "        \n",
    "        print(positive.head())\n",
    "        print(negative.head())\n",
    "        \n",
    "        pos_observations = positive.shape[0]\n",
    "        neg_observations = negative.shape[0]\n",
    "        \n",
    "        devLen = testLen = math.floor(((100 - self.trainingSplit)/2) * pos_observations * 0.01)\n",
    "        trainLen = math.floor(pos_observations * self.trainingSplit * 0.01)\n",
    "        \n",
    "        train_pos_x = list(positive['tweet'].iloc[0:trainLen])\n",
    "        train_pos_y = list(positive['sentiment'].iloc[0:trainLen])\n",
    "        dev_pos_x = list(positive['tweet'].iloc[trainLen:devLen])\n",
    "        dev_pos_y = list(positive['sentiment'].iloc[trainLen:devLen])\n",
    "        test_pos_x = list(positive['tweet'].iloc[testLen:])\n",
    "        test_pos_y = list(positive['sentiment'].iloc[testLen:])\n",
    "        \n",
    "        devLen = testLen = math.floor(((100 - self.trainingSplit)/2) * neg_observations * 0.01)\n",
    "        trainLen = math.floor(neg_observations * self.trainingSplit * 0.01)\n",
    "        \n",
    "        train_neg_x = list(negative['tweet'].iloc[0:trainLen])\n",
    "        train_neg_y = list(negative['sentiment'].iloc[0:trainLen])\n",
    "        dev_neg_x = list(negative['tweet'].iloc[trainLen:devLen])\n",
    "        dev_neg_y = list(negative['sentiment'].iloc[trainLen:devLen])\n",
    "        test_neg_x = list(negative['tweet'].iloc[testLen:])\n",
    "        test_neg_y = list(negative['sentiment'].iloc[testLen:])\n",
    "        \n",
    "        train_x = train_pos_x + train_neg_x\n",
    "        train_y = train_pos_y + train_neg_y\n",
    "        dev_x = dev_pos_x + dev_neg_x\n",
    "        dev_y = dev_pos_y + dev_neg_y\n",
    "        test_x = test_pos_x + test_neg_x\n",
    "        test_y = test_pos_y + test_neg_y\n",
    "        \n",
    "        return (train_x, train_y, dev_x, dev_y, test_x, test_y)\n",
    "    \n",
    "    def getTrainDevTestArray(self, datasets):\n",
    "        dataset_arrays = []\n",
    "        for X, Y in datasets:\n",
    "            print(f'X len: {len(X)}')\n",
    "            print(f'Y len: {len(Y)}')\n",
    "            freqs = build_freqs(X, Y)\n",
    "            X = np.zeros((len(X), 3))\n",
    "            for i in range(len(X)):\n",
    "                X[i, :]= sentiment.extract_features(X[i], freqs)\n",
    "\n",
    "            # training labels corresponding to X\n",
    "            Y = np.array(Y)\n",
    "            dataset_arrays.append(X)\n",
    "            dataset_arrays.append(Y)\n",
    "        \n",
    "        return tuple(dataset_arrays)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets:  20000\n",
      "\n",
      " *************** \n",
      "\n",
      "         sentiment                                              tweet\n",
      "1590000          1                                @michaelahills YEP \n",
      "1590001          1  need to do homework.. can't wait for LVATT.. i...\n",
      "1590002          1  @AnneSudworth Gosh, that's hectic... Tea? I'm ...\n",
      "1590003          1                @hana77  Daily:  8am - 12 midnight \n",
      "1590004          1  watching the staff in the posh Soho face cream...\n",
      "   sentiment                                              tweet\n",
      "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
      "1          0  is upset that he can't update his Facebook by ...\n",
      "2          0  @Kenichan I dived many times for the ball. Man...\n",
      "3          0    my whole body feels itchy and like its on fire \n",
      "4          0  @nationwideclass no, it's not behaving at all....\n",
      "X len: 16000\n",
      "Y len: 16000\n",
      "X len: 0\n",
      "Y len: 0\n",
      "X len: 18000\n",
      "Y len: 18000\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    tweets_df = pd.read_csv(\"data/tweets.csv\", encoding = \"ISO-8859-1\", header=None)\n",
    "#     tweets_df = pd.read_csv(\"data/tweets.csv\", encoding = \"utf-8\", header=None)\n",
    "    \n",
    "    tweets_df_1 = tweets_df.iloc[:10000]\n",
    "    tweets_df_2 = tweets_df.iloc[len(tweets_df)-10000:]\n",
    "    tweets_df = tweets_df_1.append(tweets_df_2)\n",
    "    \n",
    "    print('Total number of tweets: ',tweets_df.shape[0])\n",
    "    print('\\n *************** \\n')\n",
    "    sentiment = SentimentAnalysis(80, tweets_df)\n",
    "    tweets_df = sentiment.getCleanDataFrame(tweets_df)\n",
    "    train_x, train_y, dev_x, dev_y, test_x, test_y = sentiment.performTrainDevTestSplit()\n",
    "    train_X, train_Y, dev_X, dev_Y, test_X, test_Y = sentiment.getTrainDevTestArray([(train_x, train_y), (dev_x, dev_y), (test_x, test_y)])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Design Model (input, output, forward pass) <br>\n",
    "2. Construct loss and optimizer <br>\n",
    "3. Training Loop:\n",
    " - forward pass : compute prediction and loss\n",
    " - backward pass: gradients\n",
    " - update weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-27c25f0e4c96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sdsd'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "a = 'sdsd'\n",
    "a.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "class LogisticRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "    \n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Loss and Optimizer\n",
    "\n",
    "learning_rate = 0.01\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# training loop\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # forward pass and loss\n",
    "    y_pred = model.forward(train_x)\n",
    "    loss = criterion(y_pred, train_y)\n",
    "    # backward \n",
    "    loss.backward()\n",
    "    # updates\n",
    "    optimizer.step()\n",
    "    # reset the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch+1)%10 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
    "        \n",
    "with torch.no_grad():\n",
    "    y_pred = model.forward(dev_x)\n",
    "    y_pred_cls = y_pred.round()\n",
    "    acc = y_pred_cls.eq(dev_y).sum() / float(dev_y.shape[0])\n",
    "    print(f'Accuracy {acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
